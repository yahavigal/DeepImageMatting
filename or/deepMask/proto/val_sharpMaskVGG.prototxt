name: "Sharp Mask Net"
#-------------------4 data layers for train and test-----------------------------------
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label_rgb" #not in use
  include {
    phase: TRAIN
  }
	transform_param {
    mean_value: 104
    mean_value: 117
    mean_value: 123
 	}
  data_param {
    source: "/media/or/Data/deepMask/lmdb/train_rgb_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "data"
  type: "Data"
  top: "mask"
  top: "label_mask"
  include {
    phase: TRAIN
  }
  data_param {
    source: "/media/or/Data/deepMask/lmdb/train_mask_lmdb"
    batch_size: 32
    backend: LMDB
  }
}

layer {
  name: "data"
  type: "Data"
  top: "mask"
  top: "label_mask"
  include {
    phase: TEST
  }
  data_param {
    source: "/media/or/Data/deepMask/lmdb/test_mask_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label_rgb" #not in use
  include {
    phase: TEST
  }
	transform_param {
    mean_value: 104
    mean_value: 117
    mean_value: 123
 	}
  data_param {
    source: "/media/or/Data/deepMask/lmdb/test_rgb_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
#--------------------------common VGG 16 conv layers--------------------------------------
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 1 decay_mult: 1 }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 1 decay_mult: 1 }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 1 decay_mult: 1 }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 1 decay_mult: 1 }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 1 decay_mult: 1 }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 1 decay_mult: 1 }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 1 decay_mult: 1 }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 1 decay_mult: 1 }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 1 decay_mult: 1 }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 1 decay_mult: 1 }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 1 decay_mult: 1 }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 1 decay_mult: 1 }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 1 decay_mult: 1 }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
  relu_param{ negative_slope: 0 }
}
#-------- sharp mask specific conv to reduce the features----------
#layer {
#  name: "conv5_4"
#  type: "Convolution"
#  bottom: "conv5_3"
#  top: "conv5_4"
#	param { lr_mult: 1 decay_mult: 0 }
#	param { lr_mult: 2 decay_mult: 0 }
#  convolution_param {
#    num_output: 128
#    kernel_size: 1
# 		weight_filler { type: "xavier" }
#    bias_filler { type: "constant" value: 0 }
#  }
#}
#-----------------shared fc layer---------------
layer {
  name: "fc_shared"
  type: "InnerProduct"
  bottom: "conv5_3"
  top: "fc_shared"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 2 decay_mult: 1 }
  inner_product_param {
    num_output: 512
  }
}
#---------------------------------- segmentation branch -----------------------------------------------
layer {
  name: "fc_segm_2"
  type: "InnerProduct"
  bottom: "fc_shared"
  top: "fc_segm_2"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 2 decay_mult: 1 }
  inner_product_param {
    num_output: 3136
		weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}
# ---- reshape to 32X14X14 blob sharp mask specific ----
layer {
    name: "reshape"
    type: "Reshape"
    bottom: "fc_segm_2"
    top: "fc_segm_2_r"
    reshape_param {
      shape {
        dim: 0  # copy the dimension from below
        dim: 16
        dim: 14
        dim: 14 
      }
    }
}
#------------------------scoring branch ---------------------------------
layer {
  name: "fc_score_2"
  type: "InnerProduct"
  bottom: "fc_shared"
  top: "fc_score_2"
	param { lr_mult: 1 decay_mult: 0 }
	param { lr_mult: 2 decay_mult: 0 }
  inner_product_param {
    num_output: 1024
  }
}
layer {
  name: "relu_score_2"
  type: "ReLU"
  bottom: "fc_score_2"
  top: "fc_score_2"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "fc_score_2"
  top: "score"
	param { lr_mult: 1 decay_mult: 0 }
	param { lr_mult: 2 decay_mult: 0 }
  inner_product_param {
    num_output: 1
  }
}
#------------------ refinement module 1-----------------------
layer {
  name: "conv_rm_1_1"
  type: "Convolution"
  bottom: "conv5_3"
  top: "conv_rm_1_1"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 2 decay_mult: 1 }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
	  weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "relu_rm_1_1"
  type: "ReLU"
  bottom: "conv_rm_1_1"
  top: "conv_rm_1_1"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "conv_rm_1_2"
  type: "Convolution"
  bottom: "conv_rm_1_1"
  top: "conv_rm_1_2"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 2 decay_mult: 1 }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
	  weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "relu_rm_1_2"
  type: "ReLU"
  bottom: "conv_rm_1_2"
  top: "conv_rm_1_2"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "concat_rm1"
  bottom: "conv_rm_1_2"
  bottom: "fc_segm_2_r"
  top: "concat_rm_1"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv_rm_1_3"
  type: "Convolution"
  bottom: "concat_rm_1"
  top: "conv_rm_1_3"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 2 decay_mult: 1 }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
	 	weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "relu_rm_1_3"
  type: "ReLU"
  bottom: "conv_rm_1_3"
  top: "conv_rm_1_3"
  relu_param{ negative_slope: 0 }
}
layer {
	name: "upsampling_rm_1"
	type: "Deconvolution"
	bottom: "conv_rm_1_3"
	top: "up_rm_1"
  param { lr_mult: 0 decay_mult: 0 } 
	convolution_param {
    kernel_size: 4
	 	stride: 2
    num_output: 8
    pad:  1
    weight_filler: { type: "bilinear" }
		bias_term: false
  }
} 
#------------------ refinement module 2-----------------------
layer {
  name: "conv_rm_2_1"
  type: "Convolution"
  bottom: "conv4_3"
  top: "conv_rm_2_1"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 2 decay_mult: 1 }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  	weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "relu_rm_2_1"
  type: "ReLU"
  bottom: "conv_rm_2_1"
  top: "conv_rm_2_1"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "conv_rm_2_2"
  type: "Convolution"
  bottom: "conv_rm_2_1"
  top: "conv_rm_2_2"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 2 decay_mult: 1 }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
  	weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "relu_rm_2_2"
  type: "ReLU"
  bottom: "conv_rm_2_2"
  top: "conv_rm_2_2"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "concat_rm_2"
  bottom: "conv_rm_2_2"
  bottom: "up_rm_1"
  top: "concat_rm_2"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv_rm_2_3"
  type: "Convolution"
  bottom: "concat_rm_2"
  top: "conv_rm_2_3"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 2 decay_mult: 1 }
  convolution_param {
    num_output: 4
    pad: 1
    kernel_size: 3
  	weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "relu_rm_2_3"
  type: "ReLU"
  bottom: "conv_rm_2_3"
  top: "conv_rm_2_3"
  relu_param{ negative_slope: 0 }
}
layer {
	name: "upsampling_rm_2"
	type: "Deconvolution"
	bottom: "conv_rm_2_3"
	top: "up_rm_2"
  param { lr_mult: 0 decay_mult: 0 }
	convolution_param {
    kernel_size: 4
	 	stride: 2
    num_output: 4
    pad:  1
    weight_filler: { type: "bilinear" }
		bias_term: false
  }
} 
#------------------ refinement module 3-----------------------
layer {
  name: "conv_rm_3_1"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv_rm_3_1"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 2 decay_mult: 1 }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  	weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "relu_rm_3_1"
  type: "ReLU"
  bottom: "conv_rm_3_1"
  top: "conv_rm_3_1"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "conv_rm_3_2"
  type: "Convolution"
  bottom: "conv_rm_3_1"
  top: "conv_rm_3_2"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 2 decay_mult: 1 }
  convolution_param {
    num_output: 4
    pad: 1
    kernel_size: 3
  	weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "relu_rm_3_2"
  type: "ReLU"
  bottom: "conv_rm_3_2"
  top: "conv_rm_3_2"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "concat_rm_3"
  bottom: "conv_rm_3_2"
  bottom: "up_rm_2"
  top: "concat_rm_3"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv_rm_3_3"
  type: "Convolution"
  bottom: "concat_rm_3"
  top: "conv_rm_3_3"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 2 decay_mult: 1 }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
  	weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "relu_rm_3_3"
  type: "ReLU"
  bottom: "conv_rm_3_3"
  top: "conv_rm_3_3"
  relu_param{ negative_slope: 0 }
}
layer {
	name: "upsampling_rm_3"
	type: "Deconvolution"
	bottom: "conv_rm_3_3"
	top: "up_rm_3"
	param { lr_mult: 0 decay_mult: 0 }
	convolution_param {
    kernel_size: 4
	 	stride: 2
    num_output: 2
    pad:  1
    weight_filler: { type: "bilinear" } 
		bias_term: false
  }
}
#------------------ refinement module 4-----------------------
layer {
  name: "conv_rm_4_1"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv_rm_4_1"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 2 decay_mult: 1 }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
 		weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "relu_rm_4_1"
  type: "ReLU"
  bottom: "conv_rm_4_1"
  top: "conv_rm_4_1"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "conv_rm_4_2"
  type: "Convolution"
  bottom: "conv_rm_4_1"
  top: "conv_rm_4_2"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 2 decay_mult: 1 }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
 		weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "relu_rm_4_2"
  type: "ReLU"
  bottom: "conv_rm_4_2"
  top: "conv_rm_4_2"
  relu_param{ negative_slope: 0 }
}
layer {
  name: "concat_rm_4"
  bottom: "conv_rm_4_2"
  bottom: "up_rm_3"
  top: "concat_rm_4"
  type: "Concat"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv_rm_4_3"
  type: "Convolution"
  bottom: "concat_rm_4"
  top: "conv_rm_4_3"
	param { lr_mult: 1 decay_mult: 1 }
	param { lr_mult: 2 decay_mult: 1 }
  convolution_param {
    num_output: 1
    pad: 1
    kernel_size: 3
 		weight_filler { type: "xavier" }
    bias_filler { type: "constant" value: 0 }
  }
}
layer {
  name: "relu_rm_4_3"
  type: "ReLU"
  bottom: "conv_rm_4_3"
  top: "conv_rm_4_3"
  relu_param{ negative_slope: 0 }
}
layer {
	name: "upsampling_rm_4"
	type: "Deconvolution"
	bottom: "conv_rm_4_3"
	top: "up_rm_4"
	param { lr_mult: 0 decay_mult: 0 } 
	convolution_param {
    kernel_size: 4
	 	stride: 2
    num_output: 1
    pad:  1
    weight_filler: { type: "bilinear" }
		bias_term: false
  }
}  
#-----------------------------article-specific loss layer and accuray layers------------------------------------------------------
layer {
  name: "loss"
  type: "MaskLoss"
  bottom: "up_rm_4"
  bottom: "mask"
  bottom: "score"
  bottom: "label_mask"
  top: "loss"
}
layer {
  name: "maskAccuracy"
  type: "MaskAccuracy"
  bottom: "up_rm_4"
  bottom: "mask"
  bottom: "label_mask"
  top: "maskAccuracy"
}
layer {
  name: "scoreAccuracy"
  type: "ScoreAccuracy"
  bottom: "score"
  bottom: "label_mask"
  top: "scoreAccuracy"
}
